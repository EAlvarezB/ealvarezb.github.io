---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

		<div class="blurb">
			<h1>Research</h1>

      <p>I use quantiative social science methods to study trust in digital technology and the governance of artificial intelligence (AI). Currently, I work on the following topics: (1) public and elite opinion toward AI, (2) how the American welfare state could adapt to the increasing automation of labor, and (3) attitudes toward Covid-19 surveillance technology. I also have a research stream focused on improving survey methodology. Though rooted in political science, my work converses with a wide range of disciplines, including economics, computer science, and experimental psychology.</p>
			
			<h2>Publications</h2>

      <ol>

        <li>
  <p>
    <b>Baobao Zhang</b>, 2021. <a href = "https://osf.io/284sm/">"Public Opinion Toward Artificial Intelligence</a>." Forthcoming in the <i>Oxford Handbook of Artificial Intelligence Governance</i>.
  </p>

  <button class="collapsible">Abstract</button>
<div class="content">
  <p>This chapter in the Oxford Handbook of AI Governance synthesizes and discusses research on public opinion toward artificial intelligence (AI). This chapter synthesizes and discusses research on public opinion toward artificial intelligence (AI). Understanding citizens' and consumers' attitudes toward AI is important from a normative standpoint because the public is a major stakeholder in shaping the future of the technology and should have a voice in policy discussions. Furthermore, the research could help us anticipate future political and consumer behavior. Survey data worldwide show that the public is increasingly aware of AI; however, they -- unlike AI researchers -- tend to anthropomorphize AI. Demographic differences correlate with trust in AI in general: those living in East Asia have higher levels of trust in AI, while women and those of lower socioeconomic status across different regions have lower levels of trust. Surveys that focus on particular AI applications, including facial recognition technology, personalization algorithms, lethal autonomous weapons, and workplace automation, add complexity to this research topic. I conclude this chapter by recommending four new topics for future studies: 1) institutional trust in actors building and deploying AI systems, 2) the impact of knowledge and experience on attitudes toward AI, 3) heterogeneity in attitudes toward AI, and 4) the relationship between attitudes and behavior.</p>
</div>

</li>

      	<li>
  <p>
    <b>Baobao Zhang</b>, Markus Anderljung, Lauren Kahn, Noemi Dreksler, Michael C. Horowitz, and Allan Dafoe, 2021. <a href = "https://doi.org/10.1613/jair.1.12895">"Ethics and Governance of Artificial Intelligence Evidence from a Survey of Machine Learning Researchers</a>." <i>Journal of Artificial Intelligence Research</i>, 71, 591–666.
  </p>

<button class="collapsible">Abstract</button>
<div class="content">
  <p>Machine learning (ML) and artificial intelligence (AI) researchers play an important role in the ethics and governance of AI. To gain insight into their views, we conducted a survey of researchers who published in the top AI/ML conferences (<i>N</i> = 524). We compared these results with those from a 2016 survey of AI/ML researchers and a 2018 survey of the US public. We find that AI/ML researchers place high levels of trust in international organizations, scientific organizations, and the Partnership on AI to shape the development and use of AI in the public interest; moderate trust in most Western tech companies; and low trust in national militaries, Chinese tech companies, and Facebook. While the respondents were overwhelmingly opposed to AI/ML researchers working on lethal autonomous weapons, they are less opposed to researchers working on other military applications of AI, particularly logistics algorithms. A strong majority of respondents think that AI safety research should be prioritized and that ML institutions should conduct pre-publication review to assess potential harms. These results could inform discussion amongst researchers, private sector executives, and policymakers about regulations, governance frameworks, guiding principles, and national strategies for AI.</p>
</div>
</li>


Journal Articles (Peer-Reviewed)
---
[4] **Alvarez Barreno, Erick**. 2021. “[Ciclos políticos presupuestarios en América Latina. Un análisis de panel dinámico.](https://revistas.udea.edu.co/index.php/estudiospoliticos/article/view/344333)” In Estudios Políticos, 62, pp. 267-292. 
Paper available [here](http://ealvarezb.github.io/files/paper2.pdf)

[3] **Alvarez Barreno, Erick**. 2021. “Condiciones Institucionales para la Durabilidad de la Democracia.” In Colloquia Journal of Culture and Thought, forthcoming.
Paper available [here](http://ealvarezb.github.io/files/paper1.pdf)

Outstanding Papers and Articles (Non-Peer Reviewed)
---
[2] **Alvarez Barreno, Erick**. 2020. “[El Juego de la Cuarentena.](https://drive.google.com/file/d/1Ua61iXqLALoxec7wtWTLhZfCVcpu3AOo/view)” In Newsletter CLIVAJES, 5 (4), pp. 10-13. Ecuadorian Political Science Association.

[1] **Alvarez Barreno, Erick**. 2018. “[Entre la Excepción y la Norma: Una Aproximación Teórica al Análisis del Comportamiento Judicial en Tiempos de Crisis.](http://diposit.ub.edu/dspace/handle/2445/126336)” In Digital Archive of the
University of Barcelona.
